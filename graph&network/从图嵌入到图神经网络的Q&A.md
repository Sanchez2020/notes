# 从网络表示学习到图神经网络的若干问答

## 1.什么是网络表示学习？

**网络表示学习**也可以叫做**网络嵌入（图嵌入）**技术。

将网络**拓扑空间**嵌入到**向量空间**；

将**非欧几里得**结构数据转化为**欧几里得**结构数据；

将**不规则**数据转化为**规则**数据；

再形象地讲，就是将**非网格化**数据转化为**网格**数据。

!["什么是网络表示学习"](../assets/NL_1.png"非网格化数据转化为网格数据")

> 网络表示学习将图结构数据转化为规则结构数据。

## 2.为什么要做这种转化？

现有算法多是对规则化数据进行处理，其中的深度学习尤其有效。网络嵌入表示后，图结构数据可以直接应用现有的算法而不必重新为图结构数据设计新的算法。

!["为什么要进行网络表示学习"](../assets/NL_2.png"上游网络表示学习")

> 网络表示学习以一种迂回的方式处理图结构数据，而处理图结构数据的最终目的是下游的应用任务。

## 3.可以将网络直接表示为矩阵形式，为什么还要表示学习？

邻接矩阵是最常用的处理图结构数据的的存储方式，但是现实世界中的网络往往是**高维的**，**稀疏的**，直接使用邻接矩阵的方式*存储开销大*和*表示效率低*。（因此有人专门研究图的存储结构，因此才有压缩矩阵存储图结构，但是压缩矩阵难以直接用算法处理。）

## 4.网络表示学习的方法？

[网络表示学习模型汇总介绍](网络表示学习模型汇总介绍.md)

## 5.什么是图神经网络？

图神经网络是一种基于深度学习方法的神经网络，用于处理图结构的数据。

!["图神经网络"](../assets/GNNs.png"图神经网络架构")

> 神经网络是一种端到端的模型，图神经网络即可以处理图数据的神经网络，可以取出神经网络的中间层特征作为网络的表示。
>
> 数据以Tensor的形式表示，也作为模型的输入输出；
>
> 模型的训练过程就是Tensor在神经网络中不断地向前传播和反向传播，仿佛Tensor在神经网络中流动；
>
> 经过不断地优化，最终的模型不再变化，此时模型便可以应用了；
>
> 此时的模型已经学会了对于某个实例数据应该对应什么样的输出；
>

## 6.用图神经网络的方式获取网络嵌入表示的优势？

### 6.1 充分利用网络信息

包括网络的**结构信息**和**属性信息**。

网络的结构信息一般由网络的边关系确定，根据节点之间的距离可以指定节点的一阶邻域或$K$阶邻域；网络的属性信息一般作为节点的特征值参与训练。

### 6.2 自动提取网络的特征

通过梯度下降等优化方式，使神经网络自动拟合训练数据，避免人为设计复杂的特征表征函数。

### 6.3 提取的特征可能会更高级

接上一个优势，一般人为设计的特征表征函数是通过某些直觉设计的，往往这种表征是浅的（Shallow的）。而在数据量足够大，再通过神经网络的充分训练，有效的模型可以提取出更加高级的（Deep的，潜藏的更深的）特征。

### 6.4 这种获取嵌入表示的方法更加灵活

一般的图神经网络层都会起到特征聚合的作用，从张量形状的角度看就有降维的效果。这种降维不仅仅会增加特征的质量（用更少的特征值表征更多的原始特征），而且降维之后的维度（嵌入表示的维度）还是可以方便调控的。

!["GNNs layers"](../assets/gnns_layer.png"GNNs layer")

> 神经网络做的最多的任务是分类和回归，图神经网络也是如此，很多的图神经网络都是设计为节点分类器或图分类器。
>
> 以节点分类为例，初始的节点表示一般是一个高维向量，经过图神经网络之后的输出应该对应于某一个类别，那么图神经网络必然对节点表示进行了降维（或者说对节点向量进行了压缩，对节点的特征进行了聚合）。这里的压缩维度是可以灵活调整的（可得到自定义维度的嵌入表示）。
>
> tensor在神经网络中流动时，从一个图神经层到另一个神经层只要衔接合理（对tensor进行数值计算和形状变换的过程是合理的，不会报错）就是可以的。

另一个灵活的方面体现在对下游的应用任务上。

图嵌入的应用任务有节点分类，节点聚类，节点推荐/检索/排序，链接预测，图分类，可视化等任务。（未完待续。。。）

